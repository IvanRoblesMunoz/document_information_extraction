{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satisfied-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "manufactured-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home/ivanr/git/document_information_extraction/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding...\n",
      "Retrieving ids...\n",
      "Instantiating objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                         | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model     | BartForConditionalGeneration | 406 M \n",
      "1 | criterion | NLLLoss                      | 0     \n",
      "-----------------------------------------------------------\n",
      "406 M     Trainable params\n",
      "0         Non-trainable params\n",
      "406 M     Total params\n",
      "1,625.162 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct 14 19:31:17 2021\n",
    "\n",
    "@author: ivanr\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "import os\n",
    "\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "torch.multiprocessing.set_start_method(\"spawn\")\n",
    "\n",
    "from transformers import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, ProgressBar\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "from src.summarisation.summarisation_trainer import (\n",
    "    SummariserTrainer,\n",
    "    SummarisationDataModule,\n",
    ")\n",
    "from src.summarisation.query_suitable_articles import get_article_ids\n",
    "\n",
    "# =============================================================================\n",
    "# Statics\n",
    "# =============================================================================\n",
    "from src.summarisation.summariser_statics import (\n",
    "    RANDOM_SEED,\n",
    "    MODEL_NAME,\n",
    "    N_SAMPLE_TEXTS,\n",
    "    ENCODER_MAX_LENGTH,\n",
    "    DECODER_MAX_LENGTH,\n",
    "    TRAIN_TEST_SPLIT,\n",
    "    N_EPOCHS,\n",
    "    BATCH_SIZE,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    TORCH_DEVICE = \"cuda\"\n",
    "else:\n",
    "    TORCH_DEVICE = \"cpu\"\n",
    "    print(\"Device: \", TORCH_DEVICE)\n",
    "\n",
    "# =============================================================================\n",
    "# Main module\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    def main():\n",
    "        # --- Set random seed ---\n",
    "        print(\"Seeding...\")\n",
    "        pl.seed_everything(RANDOM_SEED)\n",
    "\n",
    "        # --- Get train and test articles ---\n",
    "        print(\"Retrieving ids...\")\n",
    "        all_ids = get_article_ids(\n",
    "            random_state=RANDOM_SEED,\n",
    "            n_sample_texts=N_SAMPLE_TEXTS,\n",
    "            max_tokens_body=ENCODER_MAX_LENGTH - 2,\n",
    "        )\n",
    "\n",
    "        article_ids_train = all_ids[: int(len(all_ids) * TRAIN_TEST_SPLIT)]\n",
    "        article_ids_test = all_ids[int(len(all_ids) * TRAIN_TEST_SPLIT) :]\n",
    "\n",
    "        steps_per_epoch = len(article_ids_train) // BATCH_SIZE\n",
    "        total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "\n",
    "        warmup_steps = total_training_steps // 5\n",
    "        warmup_steps, total_training_steps\n",
    "\n",
    "        # --- Instantiate tokenizer, model, data generator ---\n",
    "        print(\"Instantiating objects...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, return_dict=True).to(\n",
    "            TORCH_DEVICE\n",
    "        )\n",
    "\n",
    "        data_module = SummarisationDataModule(\n",
    "            article_ids_train,\n",
    "            article_ids_test,\n",
    "            tokenizer,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "\n",
    "        model_pl = SummariserTrainer(model, warmup_steps, total_training_steps)\n",
    "\n",
    "        # --- Define callbacks ---\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=\"checkpoints\",\n",
    "            filename=\"best-checkpoint\",\n",
    "            save_top_k=1,\n",
    "            verbose=True,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "        )\n",
    "\n",
    "        logger = TensorBoardLogger(\"lightning_logs\", name=\"summarisation\")\n",
    "        early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "\n",
    "        class LitProgressBar(ProgressBar):\n",
    "            def init_train_tqdm(self):\n",
    "                bar = super().init_validation_tqdm()\n",
    "                bar.set_description(\"running train ...\")\n",
    "                return bar\n",
    "\n",
    "            def init_sanity_tqdm(self):\n",
    "                bar = super().init_validation_tqdm()\n",
    "                bar.set_description(\"running sanity ...\")\n",
    "                return bar\n",
    "\n",
    "            def init_test_tqdm(self):\n",
    "                bar = super().init_validation_tqdm()\n",
    "                bar.set_description(\"running test ...\")\n",
    "                return bar\n",
    "\n",
    "            def init_validation_tqdm(self):\n",
    "                bar = super().init_validation_tqdm()\n",
    "                bar.set_description(\"running validation ...\")\n",
    "                return bar\n",
    "\n",
    "        bar = LitProgressBar(refresh_rate=0)\n",
    "\n",
    "        # -- Instantiate trainer ---\n",
    "        trainer = pl.Trainer(\n",
    "            logger=logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback, bar],\n",
    "            max_epochs=N_EPOCHS,\n",
    "            gpus=1,\n",
    "            progress_bar_refresh_rate=0,\n",
    "        )\n",
    "\n",
    "        # --- Run ---\n",
    "        print(\"Running...\")\n",
    "        trainer.fit(model_pl, data_module)\n",
    "\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-sustainability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc_info",
   "language": "python",
   "name": "doc_info"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
